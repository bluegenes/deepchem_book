{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tessa/miniconda3/envs/deepchem/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/tessa/miniconda3/envs/deepchem/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a random dataset and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((4,5))\n",
    "y = np.random.random((4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74082559, 0.16997139, 0.2178261 , 0.62008477, 0.64043808],\n",
       "       [0.30756477, 0.66993958, 0.77062414, 0.13033649, 0.61015221],\n",
       "       [0.32277995, 0.9333166 , 0.91555511, 0.54070729, 0.17170172],\n",
       "       [0.27697189, 0.50193518, 0.13327517, 0.66143032, 0.84805375]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43059509],\n",
       "       [0.16143965],\n",
       "       [0.2069391 ],\n",
       "       [0.79790076]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dc.data.NumpyDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74082559 0.16997139 0.2178261  0.62008477 0.64043808]\n",
      " [0.30756477 0.66993958 0.77062414 0.13033649 0.61015221]\n",
      " [0.32277995 0.9333166  0.91555511 0.54070729 0.17170172]\n",
      " [0.27697189 0.50193518 0.13327517 0.66143032 0.84805375]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43059509]\n",
      " [0.16143965]\n",
      " [0.2069391 ]\n",
      " [0.79790076]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(x, dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(y, dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tox21 test dataset (and explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NR-AR',\n",
       " 'NR-AR-LBD',\n",
       " 'NR-AhR',\n",
       " 'NR-Aromatase',\n",
       " 'NR-ER',\n",
       " 'NR-ER-LBD',\n",
       " 'NR-PPAR-gamma',\n",
       " 'SR-ARE',\n",
       " 'SR-ATAD5',\n",
       " 'SR-HSE',\n",
       " 'SR-MMP',\n",
       " 'SR-p53']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox21_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tox21_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<deepchem.data.datasets.DiskDataset at 0x1a2a200470>,\n",
       " <deepchem.data.datasets.DiskDataset at 0x113d87470>,\n",
       " <deepchem.data.datasets.DiskDataset at 0x119b40518>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox21_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = tox21_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 1024)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X.shape # (samples, feature vector length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783, 1024)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1024)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataset.y) # 12 data poins, called labels, for each sample. correspond to the 12 tasks above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.w.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62166"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_dataset.w) # only 62166 values are nonzero/ were measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13002"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_dataset.w == 0) # there are 13002 zeros in this array of data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep zero values around so we avoid irregularly shaped arrays. Just remember to handle missing data as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.BalancingTransformer at 0x119b40ef0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers # the data has been transformed with BalancingTransformer, which is used to correct for unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we're looking at which molecules bind to an array of targets. Most molecules do not bind to most of the targets, meaning that most of the labels are zero. So a model \"could triviallly achieve >90% accuracy by always predicting 0.\" To avoid this, \"BalancingTransformer adjusts the weights for individual data points so that the total weight assigned to every class is the same. That way the loss function has not systematic preference for any one class.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an existing model (MultitaskClassifier) on the Tox21 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.MultitaskClassifier(n_tasks=12,n_features=1024, layer_sizes =[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859.6167750282893"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=10) #an epoch is one complete pass thorugh all samples in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's usually not enough training data to get to a fully optimized model before running out of data. So we use multiple epochs to train models with smaller amounts of data (use multiple passes over same training dataset). However, the more epochs you use, the more likely you are to end up with an overfit model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dc.metrics.Metric` class provides a general way to specify metrics for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\") # np.mean == mean of ROC-AUC across all tasks is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ROC-AUC` is a popular heuristic used to summarize how well a classifier works. \n",
    "\n",
    "With this dataset, we want to classify molecules as \"toxic\" or \"non-toxic\", but the model outputs continuous numbers, not discrete predictions. In practice, we pick a threshold value over which a molecule is predicted to be \"toxic\". Choice of this threshold will affect false positive/negative rate. \n",
    "\n",
    "The ROC (receiver operating characteristic) curve helps visualize this trade-off. Try many diff threshold vals, plot a curve of the true positive rate vs. false positive rate as the threshold is varied.\n",
    "\n",
    "`ROC-AUC` is the total area under teh ROC curve. If a perfect threshold exists (every sample classified correctly), ROC-AUC is 1. With completely random output, ROC-AUC is 0.5. So we can use `ROC-AUC` to summarize how well a classifier works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9910237269226294, 0.9961323859987155, 0.9597516509854918, 0.9805740353908223, 0.9050492961128287, 0.984607949740244, 0.9914808443507592, 0.9042056020017908, 0.9883149885511855, 0.9675495723678504, 0.9464931497504032, 0.9766392571460536]\n",
      "Training ROC-AUC Score: 0.965985\n",
      "computed_metrics: [0.7954620918649695, 0.8467374810318664, 0.8957458151188826, 0.8130625915846766, 0.7147868145275496, 0.7931598264931599, 0.7228566699768288, 0.7227619004688064, 0.8488553766727804, 0.7260629531970996, 0.8683696375124709, 0.7681079083518108]\n",
      "Test ROC-AUC Score: 0.792997\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "test_scores = model.evaluate(test_dataset, [metric], transformers)\n",
    "print(\"Test ROC-AUC Score: %f\" % test_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9659852049432311}\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.7929974222334084}\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train a new MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task: classify handwritten numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘MNIST_data’: File exists\n",
      "--2019-04-25 14:09:48--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9912422 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘train-images-idx3-ubyte.gz.1’\n",
      "\n",
      "train-images-idx3-u 100%[===================>]   9.45M  5.46MB/s    in 1.7s    \n",
      "\n",
      "2019-04-25 14:09:50 (5.46 MB/s) - ‘train-images-idx3-ubyte.gz.1’ saved [9912422/9912422]\n",
      "\n",
      "--2019-04-25 14:09:50--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28881 (28K) [application/x-gzip]\n",
      "Saving to: ‘train-labels-idx1-ubyte.gz.1’\n",
      "\n",
      "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-04-25 14:09:51 (292 KB/s) - ‘train-labels-idx1-ubyte.gz.1’ saved [28881/28881]\n",
      "\n",
      "--2019-04-25 14:09:51--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1648877 (1.6M) [application/x-gzip]\n",
      "Saving to: ‘t10k-images-idx3-ubyte.gz.1’\n",
      "\n",
      "t10k-images-idx3-ub 100%[===================>]   1.57M  2.08MB/s    in 0.8s    \n",
      "\n",
      "2019-04-25 14:09:52 (2.08 MB/s) - ‘t10k-images-idx3-ubyte.gz.1’ saved [1648877/1648877]\n",
      "\n",
      "--2019-04-25 14:09:52--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Resolving yann.lecun.com (yann.lecun.com)... 216.165.22.6\n",
      "Connecting to yann.lecun.com (yann.lecun.com)|216.165.22.6|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4542 (4.4K) [application/x-gzip]\n",
      "Saving to: ‘t10k-labels-idx1-ubyte.gz.1’\n",
      "\n",
      "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-04-25 14:09:52 (140 MB/s) - ‘t10k-labels-idx1-ubyte.gz.1’ saved [4542/4542]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir MNIST_data\n",
    "!cd MNIST_data\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#one-hot encoding = convert categorical variable into integer form. \n",
    "# In this case, 1-9 are categories\n",
    "# 1 becomes [1,0,0,0,0,0,0,0,0]\n",
    "# 9 becomes [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
    "test_dataset = dc.data.NumpyDataset(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.TensorGraph(model_dir='mnist') # model_dir is required to save model somewhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, dc.models.Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the commands below here are incomplete, partly because some commands were cut off in the pdf copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem.models.tensorgraph.layers as layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = layers.Feature(shape=(None, 784))\n",
    "label = layers.Label(shape=(None,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image = layers.Reshape(shape=(None, 28,28), in_layers = feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_1 = layers.Conv2D(num_outputs = 32, activation_fn = tf.nn.relu) #incomplete?\n",
    "conv2d_2 = layers.Conv2D(num_outputs = 64, activation_fn = tf.nn.relu) #incomplete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = layers.Flatten(in_layers=conv2d_2)\n",
    "dense1 = layers.Dense(out_channels =1024, activation_fn = tf.nn.relu) # incomplete?\n",
    "dense2 = layers.Dense(out_channels = 10, activation_fn=None, in_layers= feature) # incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "smce = layers.SoftMaxCrossEntropy(in_layers=[label, dense2])\n",
    "loss = layers.ReduceMean(in_layers=smce)\n",
    "model.set_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.SoftMax(in_layers=dense2)\n",
    "model.add_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.261777402784772"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric])\n",
    "test_scores = model.evaluate(test_dataset, [metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
