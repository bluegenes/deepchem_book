{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tessa/miniconda3/envs/deepchem/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/tessa/miniconda3/envs/deepchem/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a random dataset and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((4,5))\n",
    "y = np.random.random((4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44621009, 0.51024127, 0.66014646, 0.26643113, 0.86685781],\n",
       "       [0.67478791, 0.98480084, 0.42769923, 0.70659297, 0.20465776],\n",
       "       [0.880069  , 0.14874706, 0.1930732 , 0.34216168, 0.98266257],\n",
       "       [0.76281526, 0.37601553, 0.04442908, 0.83226447, 0.97504219]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74454328],\n",
       "       [0.0949587 ],\n",
       "       [0.44730824],\n",
       "       [0.36506096]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dc.data.NumpyDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44621009 0.51024127 0.66014646 0.26643113 0.86685781]\n",
      " [0.67478791 0.98480084 0.42769923 0.70659297 0.20465776]\n",
      " [0.880069   0.14874706 0.1930732  0.34216168 0.98266257]\n",
      " [0.76281526 0.37601553 0.04442908 0.83226447 0.97504219]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.X) # capital bc is matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74454328]\n",
      " [0.0949587 ]\n",
      " [0.44730824]\n",
      " [0.36506096]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.y) # lowercase bc is vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(x, dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(y, dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tox21 test dataset (and explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from /var/folders/1c/s23lyl9x7cgd1rg4n6t867qr0000gn/T/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 19.596 s\n",
      "TIMING: dataset construction took 19.987 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.582 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.509 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.383 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.326 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NR-AR',\n",
       " 'NR-AR-LBD',\n",
       " 'NR-AhR',\n",
       " 'NR-Aromatase',\n",
       " 'NR-ER',\n",
       " 'NR-ER-LBD',\n",
       " 'NR-PPAR-gamma',\n",
       " 'SR-ARE',\n",
       " 'SR-ATAD5',\n",
       " 'SR-HSE',\n",
       " 'SR-MMP',\n",
       " 'SR-p53']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox21_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tox21_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<deepchem.data.datasets.DiskDataset at 0x1a2d3abf60>,\n",
       " <deepchem.data.datasets.DiskDataset at 0x10f239f28>,\n",
       " <deepchem.data.datasets.DiskDataset at 0x1a2d3944e0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox21_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = tox21_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 1024)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X.shape # (samples, feature vector length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(783, 1024)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataset.y) # 12 data points, called labels, for each sample. correspond to the 12 tasks above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.w.shape #weights can let you set certain labels to 0. What happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_dataset.w) # only 62166 values are nonzero/ were measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_dataset.w == 0) # there are 13002 zeros in this array of data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep zero values around so we avoid irregularly shaped arrays. Just remember to handle missing data as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.BalancingTransformer at 0x1a2d3ab5f8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers # the data has been transformed with BalancingTransformer, which is used to correct for unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, we're looking at which molecules bind to an array of targets. Most molecules do not bind to most of the targets, meaning that most of the labels are zero. So a model \"could triviallly achieve >90% accuracy by always predicting 0.\" To avoid this, \"BalancingTransformer adjusts the weights for individual data points so that the total weight assigned to every class is the same. That way the loss function has not systematic preference for any one class.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an existing model (MultitaskClassifier) on the Tox21 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.MultitaskClassifier(n_tasks=12,n_features=1024, layer_sizes =[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861.1133545890686"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=10) #an epoch is one complete pass thorugh all samples in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's usually not enough training data to get to a fully optimized model before running out of data. So we use multiple epochs to train models with smaller amounts of data (use multiple passes over same training dataset). However, the more epochs you use, the more likely you are to end up with an overfit model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dc.metrics.Metric` class provides a general way to specify metrics for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\") # np.mean == mean of ROC-AUC across all tasks is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ROC-AUC` is a popular heuristic used to summarize how well a classifier works. \n",
    "\n",
    "With this dataset, we want to classify molecules as \"toxic\" or \"non-toxic\", but the model outputs continuous numbers, not discrete predictions. In practice, we pick a threshold value over which a molecule is predicted to be \"toxic\". Choice of this threshold will affect false positive/negative rate. \n",
    "\n",
    "The ROC (receiver operating characteristic) curve helps visualize this trade-off. Try many diff threshold vals, plot a curve of the true positive rate vs. false positive rate as the threshold is varied.\n",
    "\n",
    "`ROC-AUC` is the total area under teh ROC curve. If a perfect threshold exists (every sample classified correctly), ROC-AUC is 1. With completely random output, ROC-AUC is 0.5. So we can use `ROC-AUC` to summarize how well a classifier works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9886872783244987, 0.9961725272960822, 0.9605013584685427, 0.9816490617170226, 0.9002438024313751, 0.9839427470879616, 0.9919344634776031, 0.9091163499117103, 0.9864523812837984, 0.9702288222334021, 0.9472936971856232, 0.9761481232869049]\n",
      "Training ROC-AUC Score: 0.966031\n",
      "computed_metrics: [0.7925843940232429, 0.8573034339346934, 0.8975370508583005, 0.7993510571488381, 0.715897949846402, 0.7789122455789121, 0.7169811320754718, 0.7193360079336459, 0.8525915359010937, 0.7127554383651944, 0.8655428999002328, 0.7809959349593496]\n",
      "Test ROC-AUC Score: 0.790816\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
    "test_scores = model.evaluate(test_dataset, [metric], transformers)\n",
    "print(\"Test ROC-AUC Score: %f\" % test_scores[\"mean-roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.9660308843920437}\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.7908157567104482}\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train a new MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task: classify handwritten numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: MNIST_data: File exists\n",
      "/bin/sh: wget: command not found\n",
      "/bin/sh: wget: command not found\n",
      "/bin/sh: wget: command not found\n",
      "/bin/sh: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!mkdir MNIST_data\n",
    "!cd MNIST_data\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#one-hot encoding = convert categorical variable into integer form. \n",
    "# In this case, 1-9 are categories\n",
    "# 1 becomes [1,0,0,0,0,0,0,0,0]\n",
    "# 9 becomes [0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
    "test_dataset = dc.data.NumpyDataset(mnist.test.images, mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.TensorGraph(model_dir='mnist') # model_dir is required to save model somewhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, dc.models.Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem.models.tensorgraph.layers as layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = layers.Feature(shape=(None, 784))\n",
    "label = layers.Label(shape=(None,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image = layers.Reshape(shape=(None, 28,28), in_layers = feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_1 = layers.Conv2D(num_outputs = 32, activation_fn = tf.nn.relu, in_layers = make_image)\n",
    "conv2d_2 = layers.Conv2D(num_outputs = 64, activation_fn = tf.nn.relu, in_layers=conv2d_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = layers.Flatten(in_layers=conv2d_2)\n",
    "dense1 = layers.Dense(out_channels =1024, activation_fn = tf.nn.relu, in_layers = flatten)\n",
    "dense2 = layers.Dense(out_channels = 10, activation_fn=None, in_layers= dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "smce = layers.SoftMaxCrossEntropy(in_layers=[label, dense2])\n",
    "loss = layers.ReduceMean(in_layers=smce)\n",
    "model.set_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.SoftMax(in_layers=dense2)\n",
    "model.add_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036751583300895594"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed_metrics: [0.9987454545454545]\n",
      "computed_metrics: [0.9881]\n"
     ]
    }
   ],
   "source": [
    "train_scores = model.evaluate(train_dataset, [metric])\n",
    "test_scores = model.evaluate(test_dataset, [metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
